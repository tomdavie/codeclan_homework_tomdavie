---
title: 'Manual model development'
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---


# MVP

You are given a set of data on housing sale prices for the last few years in King County (near Seattle) between May 2014 and May 2015.

<br>
<div class="emphasis">
We want you to build an **explanatory model** for the `price` of housing in King County, i.e. an interpretable model in which the included variables are statistically justifiable.

The variable definitions are:

`id` - Unique ID for each home sold  
`date` - Date of the home sale  
`price` - Price of each home sold  
`bedrooms` - Number of bedrooms  
`bathrooms` - Number of bathrooms, where .5 accounts for a room with a toilet but no shower  
`sqft_living` - Square footage of the apartments interior living space  
`sqft_lot` - Square footage of the land space  
`floors` - Number of floors  
`waterfront` - A dummy variable for whether the apartment was overlooking the waterfront or not  
`view` - An index from 0 to 4 of how good the view of the property was  
`condition` - An index from 1 to 5 on the condition of the apartment  
`grade` - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design  
`sqft_above` - The square footage of the interior housing space that is above ground level  
`sqft_basement` - The square footage of the interior housing space that is below ground level  
`yr_built` - The year the house was initially built  
`yr_renovated` - The year of the houseâ€™s last renovation  
`zipcode` - What zipcode area the house is in  
`lat` - Lattitude  
`long` - Longitude  
`sqft_living15` - The square footage of interior housing living space for the nearest 15 neighbors  
`sqft_lot15` - The square footage of the land lots of the nearest 15 neighbors  
</div>
<br>


# Question 1

Tidy up the data ready for regression:

    * You might like to think about removing some or all of `date`, `id`, `sqft_living15`, `sqft_lot15` and `zipcode` (`lat` and `long` provide a better measure of location in any event).
    * Have a think about how to treat `waterfront`. Should we convert its type?
    * We converted `yr_renovated` into a `renovated` logical variable, indicating whether the property had ever been renovated. You may wish to do the same.
    * Have a think about how to treat `condition` and `grade`? Are they interval or categorical ordinal data types?

```{r}
library(tidyverse)
library(GGally)

kc_house_data <- read_csv("data/kc_house_data.csv") %>% 
  select(-c("id", "date", "sqft_living15", "sqft_lot15", "zipcode")) %>% 
  mutate(waterfront = as.logical(waterfront),
         renovated = as.logical(yr_renovated)) 
```



# Question 2

Check for aliased variables using the `alias()` function (this takes in a formula object and a data set). [**Hint** - formula `price ~ .` says 'price varying with all predictors', this is a suitable input to `alias()`]. Remove variables that lead to an alias. Check the 'Elements of multiple regression' lesson for a dropdown containing further information on finding aliased variables in a dataset.

```{r}
alias(lm(price ~ ., kc_house_data))
```

```{r}
houses_tidy <- kc_house_data %>% 
  select(-sqft_basement)
```

```{r}
alias(lm(price ~ ., houses_tidy))
```


# Question 3

Systematically build a regression model containing up to **four** main effects (remember, a main effect is just a single predictor with coefficient), testing the regression diagnostics as you go
    * splitting datasets into numeric and non-numeric columns might help `ggpairs()` run in manageable time, although you will need to add either a `price` or `resid` column to the non-numeric dataframe in order to see its correlations with the non-numeric predictors.

<details>
<summary>**Hints**</summary>
```{r, eval=FALSE}
houses_tidy_numeric <- houses_tidy %>%
  select_if(is.numeric)

houses_tidy_nonnumeric <- houses_tidy %>%
  select_if(function(x) !is.numeric(x))

houses_tidy_nonnumeric$price <- houses_tidy$price

ggpairs(houses_tidy_numeric)
ggpairs(houses_tidy_nonnumeric)
```
and the same in subsequent rounds of predictor selection with the `resid` column.<br><br>
Remember, if you are not sure whether including a categorical predictor is statistically justified, run an `anova()` test passing in the models with- and without the categorical predictor and check the p-value of the test.
</details>

```{r}
houses_tidy %>%
  ggplot(aes(x = price, y = sqft_living)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

```{r}
library(ggfortify)
model_1 <- lm(price ~ sqft_living, data = houses_tidy)

summary(model_1)

autoplot(model_1)
```

```{r}
library(modelr)
house_tidy_remaining_resid <- houses_tidy %>% 
  add_residuals(model_1) %>% 
  select(-c("price", "sqft_living"))

house_tidy_remaining_resid %>% 
ggpairs()
```

```{r}
model_2 <- lm(price ~ sqft_living + waterfront, data = houses_tidy)

summary(model_2)

autoplot(model_2)
```


```{r}
model_3 <- lm(price ~ sqft_living + waterfront + lat:long, data = houses_tidy)

summary(model_3)

autoplot(model_3)
```

```{r}
anova(model_2, model_3)
```


```{r}
model_4 <- lm(price ~ sqft_living + waterfront + lat:long + sqft_lot, data = houses_tidy)

summary(model_4)

autoplot(model_4)
```

```{r}
anova(model_3, model_4)
```

```{r}
library(lm.beta)
```

```{r}
model_4_betas <- lm.beta(model_4)
summary(model_4_betas)
```


# Extensions

* Consider possible interactions between your four main effect predictors and test their effect upon $r^2$. Choose your best candidate interaction and visualise its effect. 

* Calculate the relative importance of predictors from your best $4$-predictor model (i.e. the model without an interaction). Which predictor affects `price` most strongly?

